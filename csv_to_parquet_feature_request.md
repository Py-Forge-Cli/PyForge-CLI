---
name: ‚ú® Feature Request
about: Suggest a new feature or enhancement for PyForge CLI
title: '[FEATURE] Add CSV to Parquet conversion with automatic delimiter and encoding detection'
labels: 'enhancement, claude-ready, feature-request'
assignees: ''
---

## ‚ú® Feature Description
Add comprehensive CSV to Parquet conversion support with intelligent auto-detection of delimiters and character encoding. This feature will allow users to convert CSV files to efficient Parquet format while preserving all data as strings, consistent with PyForge CLI's current string-based conversion approach.

## üéØ Use Case / Problem Statement
CSV files are one of the most common data exchange formats, but they lack standardization in delimiters (comma, semicolon, tab, pipe) and encoding (UTF-8, Latin-1, Windows-1252). Users currently need external tools or manual scripting to:
- Detect the correct delimiter and encoding
- Convert CSV to Parquet for efficient analytics
- Handle various CSV dialects and quirks
- Maintain data integrity during conversion

This feature would provide a seamless, automated solution for CSV processing within PyForge CLI's unified conversion ecosystem.

## üí° Proposed Solution
Implement a CSV converter that automatically detects file characteristics and converts to Parquet format:
- **Auto-detection**: Automatically identify delimiter, encoding, and quote character
- **Flexible Input**: Support various CSV dialects (comma, semicolon, tab, pipe separated)
- **String Conversion**: Convert all data to strings for consistency with other converters
- **Error Handling**: Graceful handling of malformed CSV files
- **Progress Tracking**: Progress indicators for large files
- **Validation**: Pre-conversion analysis and post-conversion verification

## üîÑ User Workflow
1. User would run: `pyforge convert data.csv`
2. The tool would: Auto-detect delimiter, encoding, and CSV structure, then convert to Parquet
3. Output would be: `data.parquet` file with all data preserved as strings

## üìã Detailed Requirements
- [ ] Support common delimiters: comma (,), semicolon (;), tab (\t), pipe (|)
- [ ] Auto-detect character encodings: UTF-8, Latin-1, Windows-1252, UTF-16
- [ ] Handle quoted fields with embedded delimiters and newlines
- [ ] Support various quote characters: double quotes ("), single quotes (')
- [ ] Process headers automatically or allow headerless files
- [ ] Convert all data types to strings for consistency
- [ ] Handle large files efficiently with chunked processing
- [ ] Provide detailed conversion progress and statistics
- [ ] Support custom output file naming and directory specification
- [ ] Include compression options (snappy, gzip, none)

## üñ•Ô∏è Command Line Interface
```bash
# Primary command
pyforge convert input.csv [output.parquet] [options]

# Example usage
pyforge convert data.csv --compression gzip
pyforge convert sales_data.csv reports/sales.parquet --verbose
pyforge convert european_data.csv --force --compression snappy
pyforge convert large_dataset.csv processed/ --verbose
```

## üìä Expected Input/Output
- **Input**: CSV files (.csv, .tsv, .txt with delimited data)
- **Output**: Single Parquet file with string columns
- **Options**: --compression (snappy/gzip/none), --force, --verbose

## üîç Technical Considerations
- **File Types**: .csv, .tsv, .txt files with delimited data
- **Performance**: Efficient processing of files up to several GB
- **Memory Usage**: Chunked processing to handle large files without excessive memory usage
- **Error Handling**: Graceful handling of malformed CSV, encoding issues, delimiter detection failures
- **Backwards Compatibility**: Follows existing PyForge CLI patterns and conventions

## üåü Alternative Solutions
- **Manual Tools**: Users currently use pandas, csvkit, or custom scripts
- **Online Converters**: Limited by file size and privacy concerns
- **Database Tools**: Require additional software and setup complexity
- **Excel Import**: Limited by row count and requires Excel software

## üìö Examples and References
Similar functionality exists in:
- **pandas**: `pd.read_csv()` with `to_parquet()`
- **csvkit**: Command-line CSV toolkit
- **Apache Arrow**: High-performance CSV reading
- **DuckDB**: SQL interface for CSV processing

## üîç Claude Implementation Guidance
```bash
# Files to examine for similar patterns
grep -r "click.option" src/pyforge_cli/
grep -r "convert" src/pyforge_cli/converters/
ls src/pyforge_cli/converters/

# Key areas to modify
# - src/pyforge_cli/main.py (add CSV support to CLI interface)
# - src/pyforge_cli/converters/ (create csv_converter.py)
# - src/pyforge_cli/plugins/registry.py (register CSV converter)
# - tests/ (add comprehensive CSV conversion tests)

# Research encoding detection libraries
# - chardet for encoding detection
# - csv.Sniffer for delimiter detection
# - pandas for robust CSV parsing

# Implementation pattern to follow
grep -r "class.*Converter" src/pyforge_cli/converters/
cat src/pyforge_cli/converters/base.py
```

## üéØ Acceptance Criteria
- [ ] CSV converter implemented following BaseConverter pattern
- [ ] CLI interface integrated with existing convert command
- [ ] Automatic delimiter detection (comma, semicolon, tab, pipe)
- [ ] Automatic encoding detection (UTF-8, Latin-1, Windows-1252)
- [ ] All data converted to string format for consistency
- [ ] Comprehensive error handling for malformed files
- [ ] Unit tests with 90%+ coverage for CSV converter
- [ ] Integration tests for end-to-end CSV conversion scenarios
- [ ] Documentation updated (CLI help, converter docs, examples)
- [ ] Performance benchmarks for large file processing
- [ ] Backwards compatibility with existing CLI interface

## üìà Success Metrics
- [ ] Users can convert CSV files of various formats without manual configuration
- [ ] Processing time under 30 seconds per 100MB CSV file
- [ ] Memory usage stays under 500MB for files up to 1GB
- [ ] Auto-detection accuracy above 95% for common CSV formats
- [ ] Error rate below 1% for well-formed CSV files

## üîó Related Issues/PRs
- Related to: Future batch processing enhancement
- Depends on: Current string-based conversion architecture
- Blocks: Advanced CSV features (schema inference, data validation)

## üìÖ Priority and Timeline
- **Priority**: High
- **Urgency**: Can Wait
- **User Impact**: Many users - CSV is extremely common data format

---
**For PyForge CLI Maintainers:**
- [ ] Feature approved for implementation
- [ ] Technical approach reviewed (encoding detection, CSV parsing strategy)
- [ ] Implementation assigned
- [ ] Design document created (CSV dialect detection algorithm)
- [ ] Implementation completed
- [ ] Code review completed
- [ ] Testing completed (unit tests, integration tests, performance tests)
- [ ] Documentation updated (converter guide, CLI reference, examples)
- [ ] Feature released